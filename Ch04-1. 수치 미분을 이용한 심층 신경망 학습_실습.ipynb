{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분을 이용한 심층 신경망 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유틸리티 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.0001 #수치미분에 필요\n",
    "\n",
    "def _t(x):\n",
    "    return np.transpose(x) #매번 입력하기 귀찮으니\n",
    "\n",
    "def _m(A,B):\n",
    "    return np.mathmul(A,B) #매트리스 곱\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x)) #sigmoid함수\n",
    "\n",
    "def mean_squared_error(h,y):\n",
    "    return 1/2 * np.mean(np.square(h-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴런 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, w, b, a) :\n",
    "        #Model Parameter\n",
    "        self.W = W #입력받은 값 저장\n",
    "        self.b = b\n",
    "        self.a = a #activation function\n",
    "        \n",
    "        #Gradients (계산해서 저장해주어야 함)\n",
    "        self.dW = np.zeros_like(self.W) #W와 똑같은 크기의 nonzero로 되어있는 numpy object(matrix) 생성\n",
    "        self.db = np.zeros_like(self.b)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        return self.a(_m(_t(self.W),x)+self.b) #activation((W^T)x + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 심층신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    def __init__(self,hidden_depth,num_neuron,num_input,num_output, activation = sigmoid):\n",
    "        #hidden layer가 몇개, hidden 하나당 neuron 몇개, input layer에 neuron 몇개, output layer에 neuron 몇개. \n",
    "        def init_var(i,o): #initialize variable 구현 i: input o: output의 뉴런(채널) 개수\n",
    "            return np.random.normal(0.0, 0.01, (i,o)), np.zeros((o,)) #0이 평균이고 0.01이 sd \n",
    "        \n",
    "        self.sequence = list()\n",
    "        #First hidden layer\n",
    "        W, b = init_var(num_input, num_neuron)\n",
    "        self.sequence.append(Neuron(W,b,activation))\n",
    "        \n",
    "        #Hidden layers\n",
    "        for _ in range(hidden_depth-1):\n",
    "            W,b = init_var(num_neuron, num_neuron)\n",
    "            self.sequence.append(Neuron(W,b,activation))\n",
    "            \n",
    "        #Output layer\n",
    "        W,b = init_var(num_neuron, num_output)\n",
    "        self.sequence.append(Neuron(W,b,activation))\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        for layer in self.sequence:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    #특정한 변수(w,b) 하나만 변화를 줘서 그때 loss가 어떻게 변화하는지 보고 numerical gradient계산하려고 함\n",
    "    #전체 네트워크를 그대로 복사를 하되 하나의 변수만 변화를 시킨걸 새로운 sequence로 만들어서\n",
    "    #다시 evaluation하는 방식\n",
    "    def calc_gradient(self, x, y, loss_func):#입력, 정답, lossfunction\n",
    "        def get_new_sequence(layer_index, new_neuron):\n",
    "            new_sequence = list()\n",
    "            for i, layer in enumerate(self.sequence): #이미 저장된 sequence사용\n",
    "                if i == layer_index:\n",
    "                    new_sequence.append(new_neuron)\n",
    "                else:\n",
    "                    new_sequence.append(layer)\n",
    "            return new_sequence\n",
    "    \n",
    "        def eval_sequence(x, sequence):\n",
    "            for layer in sequence: #새로 입력받은 sequence 사용\n",
    "                x = layer(x)\n",
    "            return x\n",
    "        loss = loss_func(self(x),y)#self = self.__init__\n",
    "        \n",
    "        for layer_id, layer in enumerate(self.sequence):\n",
    "            for w_i, w in enumerate(layer.W):\n",
    "                for w_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강 학습법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동작 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
